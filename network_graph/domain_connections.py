# -*- coding: utf-8 -*-
"""domain_connections.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WAg70dcteOo2OQMoDSym6b-tpn1esDhq

# make inverted index of domains -> users

### Import data
"""

import os
from google.colab import drive


# tweets folder contains all tweets
drive.mount('/content/drive')
dataset = '/content/drive/My Drive/covid_project/tweets'
to_save = '/content/drive/My Drive/covid_project/graph_files'
print(dataset)

"""### make dictionary < domain : accounts >"""

!pip install jsonlines

import glob
import jsonlines
from urllib.parse import urlparse

# list of 10 most cited domains, for them we use all the page
most_cited = [ 'twitter.com', 'bit.ly', 'youtu.be', 'paper.li', 'ow.ly', 'www.instagram.com', 'www.pscp.tv', 'buff.ly', 'trib.al', 'www.youtube.com']

domains = {}
for file in glob.glob(dataset+"/*.jsonl"):
  with jsonlines.open(file) as infile:
      for line in infile:
          user = line['user']['name']

          # for each domain (or page) add to dict the user
          for domain in line['entities']['urls']:
            full_url = domain['expanded_url']
            dom = urlparse(full_url).netloc
            if dom in most_cited:
              if full_url in domains:
                domains[full_url].append(user)
              else :
                domains[full_url] = [user]
            else:
              if dom in domains:
                domains[dom].append(user)
              else: 
                domains[dom] = [user]

print(f"Total domains/pages: {len(domains)}")
print(domains)

import json
import jsonlines

file = to_save + '/inverted_domains.jsonl'

with jsonlines.open(file, mode='w') as outfile:
    for entry in domains:
      val = {'domain':entry, 'users':domains[entry]}
      y = json.dumps(val) 
      outfile.write(y)