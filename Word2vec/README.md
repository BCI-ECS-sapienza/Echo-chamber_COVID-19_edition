<h1 align="center">Word2Vec - Semantic deviation</h1>

## Preprocessing
TODO

## Word2Vec
Word embedding is one of the most popular representations of document vocabulary. It is capable of capturing the context of a word in a document, semantic and syntactic similarity, relation with other words, etc.

Word embeddings are *vector representations* of a particular word.

In our work, having mined the three largest communities, we would like to know which subjects or topics are prone to be construed differently by a given echo-chamber. In order to do this, we devise a model with Word2Vec to identify the semantic deviation of each community compared to the global norm.

## Semantic Deviation
We used a set of pre-trained vectors created on a corpus of 198 million tweets as the global dataset: https://zenodo.org/record/581402#.XxMvoC2uZQI.

Using the dictionary and the vectors provided by the global dataset as initial parameters, we train a model on the tweets posted by each community. In the resulting vector-set, the deviation of a term t from community c is defined as:

<p align="center" style="text-align: center;"><img align="center" src="https://i.upmath.me/svg/%0A%5Cbegin%7Baligned%7D%0A%20%20dev(t%2Cc)%20%3D%20cosine%5C_distance(v%5Ec_t%2C%20v%5Eg_t)%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
  dev(t,c) = cosine\_distance(v^c_t, v^g_t)
\end{aligned}
" /></p>

where <img src="https://i.upmath.me/svg/v%5Et_c" alt="v^t_c"/> is the vector representation of *t* in the model created for community *c*, and *g* is the global model. We define the maximum deviation of a term as the community with the largest deviation for that term:

<p align="center" style="text-align: center;"><img align="center" src="https://i.upmath.me/svg/%0A%5Cbegin%7Baligned%7D%0A%20%20max%5C_dev(t)%20%3D%20argmax_c%20%5C%3B%20dev(t%2Cc)%0A%5Cend%7Baligned%7D%0A" alt="
\begin{aligned}
  max\_dev(t) = argmax_c \; dev(t,c)
\end{aligned}
" /></p>

---
#### Files

* **w2v_preprocessing**: TODO
* **semantic_deviation**: run Word2Vec technique on the communities generated by the Louvain algorithm. In this implementation, we use the library *Gensim*.
* **word2vec**: Word2Vec method built from scratch.

#### Reference