# -*- coding: utf-8 -*-
"""most_cited_domains_pages.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IpNXuA1HvX22X-Rm1zCq4C8oQTUMSn0o

# Most cited domains

### Import data
"""

import os
from google.colab import drive


# tweets folder contains all tweets
drive.mount('/content/drive')
dataset = '/content/drive/My Drive/covid_project/tweets'
print(dataset)

"""## Most cited domains

### make counter < domain : # tweets >
"""

!pip install jsonlines

import glob
import jsonlines
from collections import Counter
from urllib.parse import urlparse

domains = Counter()
for file in glob.glob(dataset+"/*.jsonl"):
  with jsonlines.open(file) as infile:
      for line in infile:
          for domain in line['entities']['urls']:
            full_url = domain['expanded_url']
            domain = urlparse(full_url).netloc
            domains[domain] += 1

print(f"Total domains: {len(domains)}")
print(domains)

"""### Show most cited domains"""

# print most cited domains
to_show = 20

i = 1
for domain, count in domains.most_common(to_show):
    print(f"#{i} => {domain}: {count}")
    i += 1

"""## Most cited pages"""

!pip install jsonlines

import glob
import jsonlines
from collections import Counter

pages = Counter()
for file in glob.glob(dataset+"/*.jsonl"):
  with jsonlines.open(file) as infile:
      for line in infile:
          for page in line['entities']['urls']:
            full_url = page['expanded_url']
            pages[full_url] += 1

print(f"Total pages: {len(pages)}")
#print(pages)

"""### Show most cited pages"""

# print most cited pages
to_show = 20

i = 1
for page, count in pages.most_common(to_show):
    print(f"#{i} => {page}: {count}")
    i += 1
